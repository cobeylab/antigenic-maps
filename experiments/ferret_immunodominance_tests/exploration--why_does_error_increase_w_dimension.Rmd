---
title: "Analyze ferret fits"
output: html_notebook
---

Plot how error and map tpology changes as we infer the map in higher dimensions.


```{r}
## Plot and analyze maps

rm(list = ls())
source('../../code.R')
source('../../multi_epitope_code.R')
library(foreach)
library(doParallel)
```




```{r}
parse_fits <- function(fitname # 'even', 'skewed', 'E1', 'E2', or 'E3'
                       ){
  

  input_filename <- list.files(pattern = 'inputs.rds') %>% grep(pattern = fitname, value = TRUE)
  fit_filename <- list.files(pattern = 'fit_list.rds') %>% grep(pattern = fitname, value = TRUE)
  cat(sprintf('loading files %s and %s\n', input_filename, fit_filename))
  stopifnot(length(input_filename)==1)
  stopifnot(length(input_filename) == length(fit_filename))
  inputs <- read_rds(input_filename)
  fits <- read_rds(fit_filename)
  
  fits_summary <- lapply(fits, FUN = function(ll) extract_summary_coords(stan_fit = ll))

errors_df = lapply(fits, FUN = function(ll) get_map_error_df(stan_fit = ll, titer_map = inputs$titer_map)) %>%
  bind_rows(.id = 'dimensions') %>%
  mutate(kind = fitname)
  
errors = tibble(dimensions = 1:8,
                error = sapply(fits, FUN = function(ll) get_map_error(stan_fit = ll, titer_map = inputs$titer_map)),
                kind = fitname)

return(list(inputs = inputs,
            fits = fits, 
            fits_summary = fits_summary, 
            errors_df = errors_df,
            errors = errors))
  
}
```


## Extract fits
```{r}
even_list <- parse_fits(fitname = 'even')
skewed_list <- parse_fits('skewed')
E1_list <- parse_fits(fitname = 'E1')
```

## Plot errors
```{r}
these_errors <- bind_rows(even_list$errors,
          skewed_list$errors,
          E1_list$errors) 

cowplot::plot_grid(
these_errors %>%
  ggplot(aes(x = dimensions, y = error, color = kind)) +
  geom_point() +
  geom_line(),


these_errors%>%
  filter(dimensions < 5) %>%
  ggplot(aes(x = dimensions, y = error, color = kind)) +
  geom_point() +
  geom_line()
)
```
This is unexpected. Instead, I thought that the error would approach an asymptote as dimensions increase. A map of dimension n+1 can always do at least as well as the best-fit map of dimension n, by matching the coordinates of dimension 1:n, and setting all coordinates in dimension n+1 = 0.

Some hypotheses for why we see the error increase so much as the dimensionality increases:

1. Maybe the monte-carlo error adds up as dimensionality increases?
2. Since this is posterior (integrated) error, maybe increasing uncertainty in higher dimensions leads to greater posterior predictive error, but flat median error?


## Verify that pairwise error increases with dimensionality

```{r}
plot_error_by_point <- function(parsed_list){
  parsed_list$errors_df %>%
  mutate(`map-observed distance` = predicted_map_distance-observed_distance) %>%
  ggplot() +
  geom_point(aes(x = antigen, y = `map-observed distance`, color = dimensions), alpha = .5) +
  geom_hline(aes(yintercept = 0), lty = 2)+
  facet_grid(.~serum)
}
```


```{r}
plot_error_by_point(even_list) +
  ggtitle('even fits')
```

```{r}
plot_error_by_point(skewed_list) +
  ggtitle('skewed fits')
```

```{r}
plot_error_by_point(E1_list) +
  ggtitle('E1 fits')
```

# Hypothesis 1 - monte carlo error adds up in higher dimensions

The likelihood assumes <img src="https://latex.codecogs.com/svg.image?d_{predicted}&space;\sim&space;\mathcal{N}(d_{map},&space;\sigma)" title="d_{predicted} \sim \mathcal{N}(d_{map}, \sigma)" />.

So the predictions include Monte Carlo error, whose magnitude depends on the inferred value of sigma. 

Let's look at the sigma estimates:

```{r}
## Monte carlo error depends on the standard deviation
get_sigmas <- function(parsed_fits){
  lapply(parsed_fits$fits, function(ll){
    rstan::summary(ll)$summary['sigma',]
  }) %>%
    bind_rows(.id = 'dimensions')
}
```

```{r}
sigma_results <- bind_rows(list(even = get_sigmas(even_list),
               skewed = get_sigmas(skewed_list),
               E1_dominant = get_sigmas(E1_list)),
          .id = 'kind') %>%
    extract(dimensions, into = 'dimensions', regex = '(\\d+)D', convert = T)
```
          
          
```{r}
sigma_results %>%
  mutate(xjitter = ifelse(kind == 'even', -.1, ifelse(kind == 'skewed', 0, .1))) %>%
  ggplot() +
  geom_point(aes(x = dimensions+xjitter, y = mean, color = kind)) +
  geom_segment(aes(x = dimensions+xjitter, xend = dimensions+xjitter, y = `2.5%`, yend = `97.5%`, color = kind)) +
  ggtitle('sigma estimates')
```

Ok, so it's definitely true that sigma estimates are growing as dimensionality increases, and that this could contribute to monte carlo error.

Let's estimate how much Monte Carlo error we're dealing with due to sigma.

For a given antigen-serum pair, the error is calculated as:
  $mean( \sqrt(d_{pred,i} - d_{titer})^2 )$, were $d_{pred,i}$ is the predicted distance at sample i of the posterior
  and $d_{pred,i} \sim \mathcal{N}(d_{map,i}, \sigma)$.
    
  Let's assume optimistically that $d_{map,i} = d_{titer}$ for all iterations in the posterior
  Then, the Monte Carlo error at sapmle i is:
   $M_i = |X|$, where $X \sim \mathcal{N}(0,\sigma)$
  And the overall pairwise monte carlo error is:
   $M = mean(abs(X))$
   
  Finally, we have to sum across all pairs in the analysis:
    map monte carlo error = $\sum_{antigen, serum}(M)$

```{r}
estimate_monte_carlo_error <- function(mean_sigma,
                                       niter,
                                       n_ag,
                                       n_sera){

  
  replicate(n = n_ag*n_sera, expr = {
    ## For each ag-serum pair, draw pairwise error
    M_i = abs(rnorm(niter, mean = 0, sd = mean_sigma))
    mean(M_i)
  }
  ) %>%
    sum()

  }
```




```{r}
sigma_results %>%
  rowwise() %>%
  mutate(monte_carlo_error = estimate_monte_carlo_error(mean, 2500, 5, 5)) %>%
  ungroup() %>%
  select(kind, dimensions, mean, monte_carlo_error) %>%
  rename(mean_sigma = mean) %>%
  merge(these_errors) %>%
  rename(map_error = error) %>%
  pivot_longer(contains('error')) %>%
  ggplot() +
    geom_point(aes(x = dimensions, y = value, color = kind, lty = name)) +
    geom_line(aes(x = dimensions, y = value, color = kind, lty = name)) +
    ggtitle('error sources')
```


### Ok, the plot above shows that Monte Carlo error is a huge contributor to error in higher dimensions, and that higher sigma estimates in higher dimensions drive the increase in monte carlo predictive error with increasing dimensions.


# Hypothesis 2 - median error plaueaus, but posterior error increases due to incerasing uncertainty in higher dimensions.

1. Does the variance in coordinate estimates increase with dimensionality?

```{r}
get_par_summaries <- function(parsed_fits){
  lapply(parsed_fits$fits, function(ll){
    raw_summary <- rstan::summary(ll)$summary
    summary <- as.tibble(raw_summary) %>% 
      mutate(parameter = dimnames(raw_summary)[[1]])
  }) %>%
    bind_rows(.id = 'dimensions')
}

plot_coord_ests <- function(parsed_fits){
  get_par_summaries(parsed_fits) %>%
    mutate(parameter = ifelse(parameter == 'ag2_c1', 'antigen_coords[0,1]', parameter)) %>%
    filter(grepl('coords', x = parameter)) %>%
    extract(parameter, into = c('kind', 'allele', 'coordinate'), regex = '(\\w+)_coords.(\\d+),(\\d+).$') %>%
    mutate(allele = ifelse(kind == 'antigen', as.numeric(allele)+2, as.numeric(allele))) %>%
    ggplot() +
    geom_point(aes(x = dimensions, y = mean, color = dimensions, pch = kind)) +
    geom_segment(aes(x = dimensions, xend = dimensions, y = `2.5%`, yend = `97.5%`, color = dimensions))+
    facet_grid(allele~coordinate, labeller = label_both)
}
```

```{r}
plot_coord_ests(even_list) +
  ggtitle('even immunodominance')
```

```{r}
plot_coord_ests(skewed_list) +
  ggtitle('skewed immunodominance')
```

```{r}
plot_coord_ests(E1_list) +
  ggtitle('E1 immunodominance')
```

### My interpretation of these figures:

a. The std deviation of these estimates clearly increases with dimensionality. Is this driven by a lack of identifiability?
b. The mean estimate in higher dimensions crashes to 0, but the distribution of estimates often streteches to the best c2 estimate from the 2D model, indicating again that the problem could be a lack of identifiability.

** If identifiability is the problem, we might move forward by adding a prior that adds an increasing penalty for non-zero estimates in higher dimensions.**

c. Allowing for higher dimensions does NOT allow us to infer the even map more accurately. Is this due to my choice to fix ag1 to the origin in all dimensions?

** Should I unconstrain the model?**



## 2. Does the variance in predicted distances increase with dimensionality?

--> Yes

```{r}
get_par_summaries(even_list) %>%
  filter(grepl(pattern = 'predicted', x = parameter)) %>%
  ggplot() +
  geom_point(aes(x = dimensions, y = sd), alpha = .5) +
  ggtitle('sd of predicted distances')
```

## 3. How do the mean estimated distances change with dimensionality?

```{r}
plot_distance_predictions <- function(parsed_fits){
  get_par_summaries(parsed_fits) %>%
    filter(grepl('predicted', x = parameter)) %>%
    extract(parameter, into = c('antigen', 'serum'), regex = 'predicted_distances.(\\d+),(\\d+).$') %>%
    ggplot() +
    geom_point(aes(x = dimensions, y = mean, color = dimensions)) +
    geom_segment(aes(x = dimensions, xend = dimensions, y = `2.5%`, yend = `97.5%`, color = dimensions))+
    facet_grid(serum~antigen, labeller = label_both)
}

plot_distance_predictions(even_list) +
  ggtitle('predicted distances -- even immunodominance')
```
### I'm not sure how much to make of this. It shows that the mean, and sd of predicted distances increases with dimensionality, but above we showed that this is at least partially due to monte carlo error.



## 5. How does the posterior mean error change with dimensionality?

Define posterior mean error as:
  $\sum \sqrt(d_{mean} - d_{titer})^2$, where $d_{mean}$ is the Euclidean distance between $x_{i,mean}$ and $y_{j,mean}$ where $x_{i,mean}$ is the posterior mean serum coordinate and $y_{j,mean}$ is the posterior mean antigen coordinate.
  
```{r}

get_posterior_mean_error <- function(parsed_fits){
posterior_medians <- get_par_summaries(parsed_fits) %>%
  mutate(parameter = ifelse(parameter == 'ag2_c1', 'antigen_coords[0,1]', parameter)) %>%
  filter(grepl('coords', x = parameter)) %>%
  extract(parameter, into = c('kind', 'allele', 'coordinate'), regex = '(\\w+)_coords.(\\d+),(\\d+).$') %>%
  mutate(allele = ifelse(kind == 'antigen', as.numeric(allele)+2, as.numeric(allele)))  %>%
  select(kind, allele, coordinate, mean, dimensions) %>%
  complete(kind, allele, coordinate, dimensions, fill = list(mean = 0))

get_one_distance <- function(this.antigen, this.serum, this.dimension){
  this_ag_coords = posterior_medians %>%
    filter(allele == this.antigen, kind == 'antigen', dimensions == paste0(this.dimension, 'D'), coordinate <= this.dimension) %>%
    pull(mean) 
  
  this_serum_coords = posterior_medians %>%
    filter(allele == this.serum, kind == 'serum', dimensions == paste0(this.dimension, 'D'), coordinate <= this.dimension) %>%
    pull(mean) 
  
  get_euclidean_distance(this_ag_coords, this_serum_coords)
}

pairwise_errors <- parsed_fits$inputs$titer_map %>%
  expand_grid(dimension = 1:8) %>%
  rowwise() %>%
  mutate(posterior_mean_distance = get_one_distance(this.serum = serum, this.antigen = antigen, this.dimension = dimension),
         pairwise_error = sqrt( (titer_distance - posterior_mean_distance)^2 ))
}
```


```{r}
bind_rows(list(even = get_posterior_mean_error(even_list),
               skewed = get_posterior_mean_error(skewed_list),
               E1_dominant = get_posterior_mean_error(E1_list)),
          .id = 'case') %>%
  group_by(dimension, case) %>%
  summarise(posterior_mean_map_error = sum(pairwise_error)) %>%
  ggplot() +
  geom_point(aes(x = dimension, y = posterior_mean_map_error, color = case))
```


## Ok, the posterior mean map error increases with dimension too. 

I think this is probably an identifiability issue. 

I could re-fit using the prior approach.

I could also re-calculate error, modifying the model to output map error as well as predictive error...

Or I could see what happens if I unconstrain the parameters.

  

## 6. Pairs plots for coordinates -- are pars identifiable?


```{r}
make_pairs_plots <- function(parsed_fits,
                             string_label){
  if(!dir.exists('pairs')) dir.create('pairs')
  lapply(1:8, function(ll){
    parnames <- dimnames(parsed_fits$fits[[ll]])$parameters 
    ag_parnames <- grep(pattern = 'antigen', parnames, value = TRUE)
    this_filename = sprintf('pairs/%s_%sD.png', string_label, ll)
    png(this_filename, width = 12, height = 12, units = 'in', res = 250)
    pairs(parsed_fits$fits[[ll]], pars = ag_parnames)
    dev.off()
    cat(sprintf('plot saved in %s\n', this_filename))
  }
  )}
```

```{r}
make_pairs_plots(even_list, 'even')
make_pairs_plots(skewed_list, 'skewed')
make_pairs_plots(E1_list, 'E1')
```
### In general the 3D plots point to clear identifiability issues

![E1 completely dominant - 3D pairs plot](pairs/E1_3D.png)

![even immunodominance - 3D pairs plot](pairs/even_3D.png)


These identifiability issues aren't apparent in higher dimensions, but this may be because the viable solutions are well-mixed in the 2d plane...?
![even immunodominance - 4D pairs plot](pairs/even_4D.png)

![even immunodominance - 6D pairs plot](pairs/even_6D.png)

![even immunodominance - 8D pairs plot](pairs/even_8D.png)

