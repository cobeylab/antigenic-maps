---
title: "Dimension reduction sandbox"
output: html_document
---

# What is the relationship between dimensionality of the titer matrix and dimensionality of the map.

We consider two ways to esimate matrix dimensionality:

  1. PCA - how many dimensions are needed to explain >95% of the variance?
  

# Theory:

## The definition of antigenic distance is:

* $z_{ik}$ log2 titer between strain i and serum k
* $z^{max}_{k}$ is the max observed titer between serum k and any strain
* $x_{m,i}$ is the mth coordinate of strain i
* $x_{m,k}$ is the mth coordinate of serum k
* $n_{dim}$ is the number of dimensions in Euclidean space

$$ z_{ik} = z^{max}_k - d_{ik} $$
$$ z_{ik} = z^{max}_k - \sqrt \sum_{m=1:n_{dim}}(x_{m,i}-x_{m,k})^2 $$

If we define $\delta_{m.ik}=(x_{m,i}-x_{m,k})^2$, we can re-write this as:

$$ z_{ik} = z^{max}_k - \sqrt \sum_{m=1:n_{dim}}\delta_{m,ik} $$

This isn't a linear equation, but we can identify $n_{dim} + 1$ parameters:

* There is one distance component for each dimension in $n_{dim}$
* There is an intercept, $z_k^{max}$

**--> Thus, we might expect the first ($n_{dim}+1$) principal components to explain the majority of the variance.**

Let's test this:


```{r, include=F, echo=F}
library('doParallel')
library('tidyverse')
source('../../code.R')
```


## 1. Test the hypothesis for titers generated to represent a 1D Euclidean map:

Use the formula 

$$ z_{ik} = z^{max}_k - \delta_{1,ik} $$

to simulate titer for all possible combinations of $z_k^{max}$ and $\delta_{1,ik}$.

```{r echo=F}
z_max = 10
get_one_titer_1D <- function(z_max, xi, xk, c = 1){
  z_max - sqrt((xi-xk)^2)
}

titer_df_1D <- expand_grid(x_strain = 1:10,
            x_serum = 1:10) %>%
  rowwise() %>%
  mutate(titer = get_one_titer_1D(10, x_strain, x_serum))

titer_mat_1D = matrix(titer_df_1D$titer, nrow = 10, ncol = 10, byrow = F, dimnames = list(paste0('strain', 1:10), paste0('serum', 1:10)))

titer_mat_1D
```

### Perform PCA on 1D titers
```{r}
PCA_1D <- prcomp(x = titer_mat_1D, scale = TRUE, center = TRUE)
summary(PCA_1D)
```


### Plot the variance explained
```{r echo=FALSE}
tibble(component = factor(1:10, labels = paste0('PC', 1:10)),
       variance_explained = summary(PCA_1D)$importance[2,],
       cumulative_var_explained = cumsum(variance_explained)) %>%
  ggplot() +
  geom_bar(aes(x = component, y = variance_explained), stat = 'identity') +
  geom_point(aes(x = component, y = cumulative_var_explained), color = 'deepskyblue') +
  geom_line(aes(x = as.numeric(component), y = cumulative_var_explained), color = 'deepskyblue')  +
  ggtitle('PC1 and PC2 explain >97% of the variance')
```


As expected when Euclidean distances follow a 1D model, we need 2D to represent the titer matrix.
Presumably, D1 represents the linear decrease in titer with distance, and D2 represents the peak titer for each dimension (intercept)?

### Try rank estimation with svd
```{r, echo = F, as.is=T}
cat(sprintf('The singular values of the 1D titer matrix are:\n'))
svd(titer_mat_1D)$d
```
The rank of this matrix is much greater than 2, as none of the singular values are 0.

But the first two singular values are much greater than all others, indicating that the first two dimensions explain a substantial amount of the variance.

```{r, echo = F, as.is=T}
plot(svd(titer_mat_1D)$d, xlab = 'dimension', ylab = 'singular value')
abline(b=0, r = 0)
```


## Visualize
```{r echo = FALSE}
# ggbiplot::ggbiplot(PCA_1D, labels = rownames(titer_mat_1D)) +
#   ylim(c(-2, 2)) + xlim(c(-2,2))
```

# Extend to 2D

If the above interpretation is true, then if we define the titer model in 2D, we should need 3 dimensions to represent the titer map.


### 2D model:

$z_{ik} = z^{max}_k - c(\sqrt(\delta_{1,ik}+\delta_{2,ik})$


### Simulate 2D titers
```{r echo=F}
get_one_titer <- function(z_max, xi, xk, ndim = 1, c = 1){
  stopifnot(length(xi) == length(xk))
 # cat(sprintf('xi is %s\n', xi))
  stopifnot(length(xi) == ndim)
  this.dist = get_euclidean_distance(xi, xk)
  #cat(sprintf('this distnace is %s\n', this.dist))
  z_max - this.dist
}

titer_df_2D <- expand_grid(x1_strain = 1:10,
                           x2_strain = 1:10,
            x1_serum = 1:10,
            x2_serum = 1:10) %>%
  group_by(x1_strain, x2_strain) %>%
  mutate(strain_id = 1:100) %>%
  ungroup() %>%
  group_by(x1_serum, x2_serum) %>%
  mutate(serum_id = 1:100)

titer_df_2D$titer = foreach(xi1 = titer_df_2D$x1_strain,
        xi2 = titer_df_2D$x2_strain,
        xk1 = titer_df_2D$x1_serum,
        xk2 = titer_df_2D$x2_serum,
        .combine = 'c') %do% {
          get_one_titer(z_max = 10, xi = c(xi1, xi2), xk = c(xk1, xk2), ndim = 2, c = 1)
        }


titer_mat_2D = matrix(titer_df_2D$titer, nrow = 100, ncol = 100, byrow = F, dimnames = list(paste0('serum', 1:100), paste0('strain', 1:100)))
```

### Perform PCA on 1D titers
```{r}
PCA_2D <- prcomp(x = titer_mat_2D, scale = TRUE, center = TRUE) 
summary(PCA_2D)
```

### Plot the variance explained
```{r echo=F}
tibble(component = factor(1:100, labels = paste0('PC', 1:100)),
       variance_explained = summary(PCA_2D)$importance[2,],
       cumulative_var_explained = cumsum(variance_explained)) %>%
  ggplot() +
  geom_bar(aes(x = component, y = variance_explained), stat = 'identity') +
  geom_point(aes(x = component, y = cumulative_var_explained), color = 'deepskyblue') +
  geom_line(aes(x = as.numeric(component), y = cumulative_var_explained), color = 'deepskyblue')  +
  ggtitle('PC 1:3 explain >96% of the variance')
```

### Try rank estimation with svd
```{r, echo = F, as.is=T}
cat(sprintf('The singular values of the 2D titer matrix are:\n'))
svd(titer_mat_2D)$d
```
The rank of this matrix is much greater than 2, as none of the singular values are 0.

But the first three singular values are much greater than all others, indicating that the first three dimensions explain a substantial amount of the variance.

```{r, echo = F, as.is=T}
plot(svd(titer_mat_2D)$d, xlab = 'dimension', ylab = 'singular value')
abline(b=0, r = 0)
```

Again, the number of dimensions needed to represent most of the variance is $n_{dim}+1$.





## Conclusion: 

1. If we preform PCA on a titer matrix, the number of dimensions needed to accurately represent the matrix in an antigenic map should be equal to (R-1), where R is the number of dimensions to explain most of the variance. (As a rule of thumb, we can assume the first R dimensions explain >95% of the variance).
2. Low dimensional maps imply that the titers observed in different sera have a high level of covariance.


## Interpretation/next steps:

1. If we simulate strain-level titers derived from multiple epitopes, what do we observe in PCA?
2. If we run PCA on empirical titer matrices, what do we observe?
3. If we run PCA on titer matrices that incorporate more than one immune history, or immunodominance type, what do we observe?




